A method and mechanism used for or by, individuals, groups, corporations, (profit and non profit), professionals, businesses, schools, governments, institutions, and machines to help, protect, create, design, record, file, document, publish, authenticate, plan, market, personalize, distribute, manufacture, license, franchise, sponsor, advertise, publicize, track, project, calendar, voting, rate, conference, rent, lease, price, request, propose, order, pay, fund, buy, sell, lend, bank, finance, store, insure, barter, gift, repair, service, build, share, check, insure, install, learn, teach, research, promote, collaborate, adopt, think, monitor, manage, remind, administer, broadcast, target spatial points, communicate, manage energy communication, connect like minded people, offer self help, manage group health, combined with data aggregated from a vision engine, hearing engine, touch engine, taste engine, smell engine, with data from the mechanical internet, the life Internet, and fuzzy logical, abductive, inductive, deductive, and backward chaining reasoning, to give forward suggestions, proposals, decisions, information and search in a network and non network.
Claims 1. (canceled) 2. (canceled) 3. (canceled) 4. (canceled) 5. (canceled) 6. (canceled) 7. (canceled) 8. (canceled) 9. (canceled) 10. (canceled) 11. (canceled) 12. (canceled) 13. (canceled) 14. (canceled) 15. (canceled) 16. (canceled) 17. (canceled) 18. (canceled) 19. (canceled) 20. (canceled) 21. A method for human identification; registration; and protection executed by a computer comprising: A. providing a 3D camera; audio and video recorder; a viewer; a RFID tag reader a coder and decoder; and an infrared reader; initiating a motion detector; aggregating and comparing background with foreground automatically for 3D verification; determining an infrared distance between the camera and a person; forming a pixel box around any moving objects; centering crosshairs on the nose of a person; locking on to the face of the person; storing the data aggregated in video form; extracting and storing a first image; transforming the image utilizing a brightness modified interpolation method; B. initiating a modified color interpolation method on the images; converting the images to vector line art and storing the files; establishing the center locked on point and identifying human eyes as a marker for all other processes; locking on the image with 16 pixels around the edge of the person's face; storing the image file for further analysis; recording the streamed video with an audio phrase spoken by the person; C. converting the original 3D video audio files and sending the images to a process server for storing the images; providing a server for storage; security; human key and tracking features; transforming the images utilizing the brightness modified interpolation method initiated on the original images; storing the data with a plurality of levels each way darker and lighter; transforming the images utilizing a color modified interpolation method; storing the data with a plurality of levels of red, green and blue color up and down from actual original image color data; using a Fourier wave transformation to convert the images; mapping out the pixel position of the converted images into a RGB grid PPM file; converting the files pixels into RGB numbers and then storing the data for later analysis D. converting the audio files into an audio wave form pattern and storing the data; converting the audio into images and storing the files; performing a Fourier wave transformation on the original files and storing the files; mapping out the pixel position into a RGB grid PPM file; converting the pixels into RGB numbers and storing the data for later analysis; E. converting original video files into images; extracting a plurality of images at the beginning of audio phrase spoken; extracting a plurality of images at selected mark of audio phrase start; extracting a plurality of images backward at end of audio phrase stop; storing the extracted images; transforming the images with a brightness modified interpolation method which is initiated on the images and storing the files in a plurality of levels each way darker and lighter; using a color modified interpolation method on the images and storing the files in a plurality of levels of red, green and blue color up and down from actual original image color data; performing a Fourier wave transformation and storing the data; mapping out the pixel position of the image data into a RGB grid PPM file; converting the pixels into RGB numbers; storing the data for later analysis; F. extracting a plurality of random image slices from the original video file; extracting an image slice from the beginning of the audio track where an audio phrase starts; extracting an image slice from the middle of the audio track phrase; extracting an image slice from the end of audio phrase spoken track; storing the image slices; transforming the images utilizing the brightness modified interpolation method; storing the data in a plurality of individual levels each way darker and lighter; initiating the color modified interpolation method; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the images into an octal dump; storing the octal dump for later analysis; G. extracting images created from the original video and storing the files; transforming the images utilizing the brightness modified interpolation method initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images and storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; transforming the images by performing an average color matrix analysis; storing the resulting images; converting the data to PPM files and storing the files; processing the PPM files using the brightness modified interpolation method; processing the data in a plurality of levels on all pixels and saving the data into files for later pattern analysis; H. verifying that the original video was of an actual 3D live human; using specific point movement analysis that compares the background to the foreground identifying movement patterns; extracting images from the original video; transforming the images utilizing the brightness modified interpolation method; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images and storing the data in a plurality of levels of red, green and blue color up and down from the actual original image color data; reducing the images to just two colors for evaluation; storing those images if the object is a real 3D live human for further analysis; storing audio from the video; processing the video and audio; verifying the files; storing the files during the verification state; determining the video and audio spatial point targets utilizing sound wave analysis and infrared distance analysis information taken from the storing for later analysis; I. then the Human Semantic Phrase Comparative Analysis "G" Processor mechanism; comparing the original audio to a phrase typed at registration and spoken; converting the audio into an image file; converting the file using a Fourier wave transformation and storing the file for further analysis; converting the image file to a PPM file; mapping the RGB coordinates of the PPM file into a pattern matching grid; populating the grid and storing if for later analysis; J. taking original video and original audio input and storing the files; extracting images from the original video files and stored, transforming the images utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from the actual original image color data; performing a Fourier wave transformation on the images; converting the original audio files using a Fourier wave transformation into specimen files and storing the files; converting all the specimen files into an octal dump; performing code matching on the octal dump files and storing in a database for later analysis; K. taking original video and original audio and storing the files; initiating the Fourier wave transformation on the files and storing the converted files; creating a 3D model; determining spatial points from the 3D model; performing analysis of the spatial points and calculating the files into numbers and storing for later analysis; L. receiving audio input storing it into files; overlaying with the octal dump from step F with the populated grid from step I; mapping out a grid into a file and then storing the file; converting the file into numbers and storing for later analysis; M. taking original video and audio input and storing it into files; transforming the video into images tracked and encoded with audio and storing the files; transforming the image utilizing the brightness modified interpolation method which initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the video and audio files using a Fourier wave transformation; performing a maximum distance analysis; performing a mean distance analysis; performing a mathematical error/data fit analysis; performing a average color matrix analysis; performing a fractal dimensions comparisons analysis; performing an audio wave form pattern analysis; storing the data; converting the audio into images tracked and encoded with video; mapping out the pixel position into a grid; converting the image file to a PPM file; converting the pixels into RGB numbers; storing the data for later analysis; N. taking original video and storing it into files; converting the video into images and storing the image files; transforming the image utilizing the brightness modified; initiating a brightness interpolation method on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method is initiated on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the files into gray scale images and storing the files; converting the files into vector line art images that are stored, mapping out the pixel positions of the vector line art images into a grid and storing the files; converting the pixels into numbers; and then storing the data for later analysis; O. taking original video input and storing it into files; converting original video into images and storing the files; transforming the images utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the resulting video image files using a Fourier wave transformation mechanism; converting the files into a plurality of gray scale color images; storing the images; mapping out the pixel position into a grid and storing the image files as PPM files; converting the pixels of the files into RGB numbers; then the mechanism storing the data for later analysis; P. taking original video input and storing it into files; converting original video into images; mapping the images to the audio that is input and is tracked and storing the files; mapping out the pixel positions into a grid with a plurality of bands; extracting images from band areas after audio phrase speaking starts and storing the files; transforming the image utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; creating a Fourier wave transformation form analysis file and storing it; creating levels of lightness and darkness; converting the image file to a PPM file and it is stored, converting the pixels into RGB numbers patterns; storing the data for analysis; Q. taking the original video input and storing it into files; converting the original video into images and storing the images; transforming the images utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels red, green and blue color up and down from actual image data; calculating a pixel edge around facial features and storing the files; locking in on the human eyes and the tip of the nose; calculating and triangulating distance from the center point of eye to eye and from center point of nose; mapping out the pixel position of the edge pixels and then the eye areas and nose areas into a grid and storing the files; converting the image file to a PPM file and storing it; converting the pixels into RGB numbers and then storing the data for later analysis; R. taking original video and audio input and storing it into files; extracting the audio from a video left and right stereo; saving the data as two separate files; initiating the Fourier wave transformation mechanism converting files to wave form data; and storing the files as image files; converting the files data to numbers and storing the data; overlaying and aligning the wave forms from the two image files and storing the files; analyzing aligned wave form data and creating new numbers and storing the files; analyzing 3D distance variations for a test of real object and not flat field object; S. comparing information from the registration and the sign in files; calculating percentages that are positive matches versus percentages that are negative matches for verification; T. registering a human key by looking into the crosshairs on the display screen and speaks a phrase recorded by a person with audio and video; storing and analyzing the audio and video; confirming a uniquely identified registered user; using the system to lock; protect, and unlock single items; U. confirming a person looking at the cam and while talking or saying a phrase and recording background objects; determining whether an object being viewed by the camera is a 3 dimensional object for verification; comparing the camera results and analyzing the files in an overlay pixel pattern analysis method; calculating position of forward focused objects; calculating position and depth of background focused objects; calculating the difference between forward focused objects and background focused objects and determining a value; using the value to determine a 3-D preliminary security decision; creating an audio voice print with input; comparing a first audio print to the last audio print; making a file security decision; 22. The method of claim 21 further comprising beginning aggregation and comparing background with foreground automatically for 3D verification when a motion detector is triggered, storing the data; forming a pixel box around any moving or non-moving objects; so when an object is centered in crosshairs, the system and mechanism is locked on to the object and storing that data aggregated in video form; extracting a first image when the lock on instigates and storing the image; transforming the image utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green, and blue color up and down from actual original image color data; converting the images to vector line art and storing the files; establishing a center locked on point along with the top of the object identified as a marker for all other processes; locking on the image with 16 pixels around the edge of the object; storing the image file for further analysis; recording and storing the streamed video; extracting three random image slices from the video file; extracting one image from the beginning of the video track; extracting one image from the middle of the video track; extracting one image from the end of video track; storing the image slices; transforming the images utilizing the brightness modified interpolation method; storing the data in a plurality of individual levels each way darker and lighter; initiating the color modified interpolation method; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting images into an octal dump and storing the data for later analysis; extracting images created from the original video and storing the files; transforming the images utilizing the brightness modified interpolation method; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; transforming the images with the average color matrix analysis mechanism; storing the resulting images; converting the data to PPM files and storing the files; processing the PPM files with the interpolate brightness method; processing the data in a plurality of levels on all pixels; saving the data into files for later pattern analysis; taking original video input and storing it into files; converting the video into images and storing the image files; transforming the image utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the files into gray scale images and storing the files; converting the files into vector line art images that are stored; mapping out the pixel positions of the vector line art images into a grid and storing the files; converting the pixels into numbers; and then storing the data for later analysis; taking original video input and storing it into files; converting original video into images and storing the files; transforming the images utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the resulting video image files using a Fourier wave transformation mechanism and the files are stored; converting the files into 16 gray scale color images and storing the images; mapping out the pixel position into a grid and storing the image files as PPM files; converting the pixels of the files into RGB numbers; storing the data for later analysis; taking original video input and storing it into a file; initiating the Fourier wave transformation mechanism on the file and storing the converted file; creating and storing a 3D model; determining spatial points from the 3D model and storing them in a database; calculating the spatial points into numbers; storing the numbers for later analysis; taking original video input and storing it into a file; transforming the video into images tracked and encoded and storing the file; transforming the image utilizing the brightness modified interpolation method which is initiated on the images; storing the data in a plurality of levels each way darker and lighter; initiating the color modified interpolation method on the images; storing the data in a plurality of levels of red, green and blue color up and down from actual original image color data; converting the video files d using a Fourier wave transformation and storing the files; analyzing the data; running a maximum distance analysis; running a mean distance analysis; running a mathematical error/data fit analysis; running an average color matrix analysis; running a fractal dimensions comparisons analysis; running a audio wave form pattern analysis; storing the data; converting the audio into images tracked and encoded with video; mapping out the pixel position into a grid and creating a file; converting the file to a PPM file and storing it; converting the pixels into RGB numbers; storing the data for later analysis; taking comparison information from a object registration processor; performing pattern matching with a new object data from the object identification processor; calculating percentages that are positive matches versus percentages that are negative matches for verification; returning a match combined with positive point evaluations or a non-match combined with negative point evaluations; providing a data aggregator system mechanism; recording comments on content; providing a checks and balance system to determine the value of the content or comment; determining advertising placement by bids; buying and selling advertisements and locations; receiving bids for advertising position; purchasing advertising; directing the advertising revenue; targeting advertisements using the human key to spatial points for distribution to viewers; identifying individuals with a rating to establish the identity of a person; authenticating to establish as genuine using the human key; verifying to prove the truth of identity of a person; providing a touch engine that aggregates touch items into data; providing a smell engine that aggregates smell items into data; providing a hearing engine that aggregates audio items into data; providing a vision engine that aggregates vision items into data; providing a reasoning engine that provides intelligent suggestions, proposals, and decisions; using data from the sense engines, and data stored in computers by the reasoning engine to provide intelligent suggestions, proposals, and decisions; and use the reasoning engine in parallel with a databases for hypothesis creations and suggestions. 23. The method of claim 21 and further comprising managing a solar panel array; providing electronic wireless transfer to an inverter; storing energy in individual or community batteries for later distribution; providing a kilowatt hour bank and payment mechanism; automatically calculating value and various correlations with costs of products and items that are currently used in the world in a database of kilowatt hours as related to dollars and other different legal currencies; providing a kilowatt hour pricing comparison to a product registry mechanism; providing an energy efficient manager mechanism; providing a demand charge Manager mechanism; calculating world geo kilowatt hour rates; providing a kilowatt hour pay module mechanism; protecting with a human key; storing, banking and trading energy as currency; providing an energy switch adapter and measurement mechanism for kilowatt hour use; and switching the adapter off by an energy management solar server unit remotely. 24. The method of claim 21 and further comprising determining spatial point targets for streaming content; recording and delivering content via the camera to spatial point targets in 3D or standard media; displaying a whole store or parts of the store into a person's home at a marked spatial point target locations for viewing and shopping; mapping of a house or real estate to spatial point targets. 25. The method of claim 22 further comprising using information from the database and a product object registry mechanism; and creating a request. 26. The method of claim 21 further comprising setting a reminder; distributing the reminder to one or more recipients; providing access only to the person who the reminder was intended for; requiring digital fingerprint verification and identification; delivering the reminder or broadcasting the reminder to spatial point targets. 27. The method of claim 22 further comprising providing RFID chip identification; providing invisible infrared ink marker identification coding; providing a video infrared reader; reading infrared invisible ink; providing an infrared invisible ink stamper; stamping a code stamp pattern on a product or product packaging; rapidly coding with patterns changing to different codes as each product or product packaging goes through the process; reading either optically with infrared or an RFID tag reader; encoding and decoding with the infrared reader; providing information from a product registry where information about a product is included into the product registry; using spatial point targeting to deliver product information to a specific location; tracking information for inventory control; integrating consumer information with product information; and providing a consumer rating on a product. 28. The method of claim 21 further comprising locking and unlocking access using the cross hair lock; identifying the owner(s) of the lock; determining who the lock is registered to; and locking or unlocking the lock. 29. The method of claim 22 further comprising providing camera tracking manually or automatically moving from the front to the back of a room, and rotating 360 degrees; recording the entire room events; and attaching a human key for protection, storage, and distribution to one or more recipients of the recording. 30. The method of claim 22 and further comprising; a barter network; suggesting potential best barter deals; adding proposals and suggestions from business or individuals to the barter network; listing services or e property for barter on the barter network; providing a rating shield; estimating barter value; estimating real value; estimating barter value and real value for professional services that are willing to trade for other bartered items or services; rating the deal and recording the deal for future barter deals; and notifying members with best choice combinations. 31. The method of claim 21 further comprising processing collaborated data or content into a new work; uploading first content created to a server by a first user; protecting the first content; attaching the first content to a first user's human key; uploading second content created to a server by a second user; protecting the second content; attaching the second content to a second user's human key; licensing the rights to the first and second content by a third user; combining the first and second content together by the third user; notifying the parties after the combined content is created; attaching the combined content to a human key; recording a history of whose human key was involved in creating the combined content; sharing the list of created works; storing the works on a server; attaching a human key to all incoming and outgoing content; monitoring and managing a list of combined content; distributing and sharing content; including all content in a catalog for others to browse safely and protected for licensing; proposing and approving outright purchase or license of the content by the human key attached to the content; accepting payment for any purchase or license; and distributing collected payments. 32. The method of claim 21 further comprising identifying a person using an ATM; verifying the person is the registered owner of the account; and performing financial transactions only for the registered owner of the account. 33. The method of claim 21 further comprising connecting individuals and groups together utilizing network devices; enabling users to pick their own spatial point target for delivery of other users live or recorded images; transforming content into a 3D representation; and placing 3D content around a table virtually. 34. The method of claim 21 further comprising using a human key by a licensed medical care practitioner to transmit secure information; attaching a human key to the information; viewing or transmitting information to a spatial point target; using the human key to register and identify a patient; providing an alert and reminder, to remind patients when to take their medications as well as reminding patients when they last took their medications and the quantities taken; recording and transmitting alert and reminder information into patient journals and doctor journals using the human key; and allowing patients to securely talk to their doctor(s) or other securely and communicate information. 35. The method of claim 21 further comprising converting mobile devices for 3D recording and viewing; recording and viewing in 3D with a split screen, with a two camera view; creating a split screen 3D display viewing area; providing streaming media to and from a server online; and streaming media can delivered to spatial point targets. 36. The method of claim 21 furthermore comprising looking into the camera by a uniquely identified individual; stating a phrase by the individual; verifying the individual; requesting a payment transaction; and authorizing the payment transaction. 37. The method of claim 21 furthermore comprising using the human key to uniquely identify and verify a person; registering an identified and verified person to vote; casting a vote by an identified and verified person registered to vote; and certifying only one vote per identified and verified person registered to vote has be placed. 